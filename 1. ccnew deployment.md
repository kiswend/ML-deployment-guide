New control center deployment


# Deploy the control center host

## create the SSH key pair

The pair of keys will be used for the VM SSH authentication. They can be done on AWS during the VM creation process

## save the private key on the local computer for later use

vi ~/.ssh/ml-perf-ccu-host-private-key
```txt
-----BEGIN RSA PRIVATE KEY-----
***
-----END RSA PRIVATE KEY-----
```

set the correct file privilege as per ssh requirements

```bash
chmod 400 ~/.ssh/ml-perf-ccu-host-private-key
```

## Create a small VM in AWS to host the control center util.

create a VM with below requirements:
- OS: Ubuntu 24.04 LTS
- user: default ubuntu & root
- ubuntu untentication: SSH key
- size: t3.small


## Login the ccu host
```bash
ssh -i ~/.ssh/ml-perf-ccu-host-private-key ubuntu@13.53.137.216

sudo su
apt-get update && apt-get upgrade -y

# install tmux
```bash
apt install tmux
tmux -V
```

## Install docker

```bash
# refer to the official documenation https://docs.docker.com/engine/install/ubuntu/

# remove any conflicting package
for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done

# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
# install
apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```


## Create aws credentials
```bash
mkdir ~/.aws/

# cat <<EOF > ~/.aws/config
# [default]
# region = eu-west-2
# EOF

cat <<EOF > ~/.aws/credentials
[oss]
aws_access_key_id = changeme
aws_secret_access_key = changeme
EOF
```

# AWS setup

## Prepare AWS the_admin policy

```bash
#Create the group
aws iam create-group \
  --group-name iac_admin \
  --profile mojaiac

#Attach the AdministratorAccess policy
aws iam attach-group-policy \
  --group-name iac_admin \
  --policy-arn arn:aws:iam::aws:policy/AdministratorAccess \
  --profile mojaiac
```


# Control center util (CCU)

## run the container
```bash
# we use tmux to make sure the terraform apply won't be interrupted if the SSH drops
tmux new -s ml-perf-ccu-4 

# start the control center util container
docker run -it -d \
    -v ~/.aws:/root/.aws \
    --name ml-perf-ccu-4 \
    --hostname ml-perf-ccu-4 \
    --cap-add SYS_ADMIN \
    --cap-add NET_ADMIN \
    ghcr.io/mojaloop/control-center-util:6.1.2 

# connect to the container
docker exec -it ml-perf-ccu-4 bash
```

## Edit en IaC module version
```bash
cd /iac-run-dir
vi setenv
```

update the setenv file content as below to set the IAC_TERRAFORM_MODULES_TAG to desired value

```bash
export AWS_PROFILE=oss
export PRIVATE_REPO_TOKEN=nullvalue
export PRIVATE_REPO_USER=nullvalue
export ANSIBLE_BASE_OUTPUT_DIR=$PWD/output
export IAC_TERRAFORM_MODULES_TAG=v5.9.0 # set version
export PRIVATE_REPO=example.com
```

## initialize
```bash
source setenv
./init.sh
cd /iac-run-dir/iac-modules/terraform/ccnew/
```

## update environment file

### cluster config
```bash
vi /iac-run-dir/iac-modules/terraform/ccnew/custom-config/cluster-config.yaml
```

customize the content of environment.yaml according to the requirements.
```yaml
cluster_name: cc004 # may be changed according to naming plan
domain: perf004.mojaperflab.org # to change match your DN
cloud_region: eu-north-1 # to chanage
ansible_collection_tag: v5.5.0-rc3
iac_terraform_modules_tag: v5.9.0
letsencrypt_email: ndelma@mojaloop.io # to change
tags: # to change
  Origin: Terraform
  mojaloop/cost_center: mlf-perf004-cc
  mojaloop/env: ft-sbox-rw
  mojaloop/owner: Nathan-Delma
```

### Environments

List the environments to preconfigure. This can be edited after the control center deployment to add, modify or remove.

```bash
vi /iac-run-dir/iac-modules/terraform/ccnew/custom-config/environment.yaml
```

```yaml
environments:
  - sw004
  - pm004
```


## Deploy the control center

```bash
./wrapper.sh 
```

## Move the terraform state to the control center

```bash
./movestatetok8s.sh
```

# Control center (CC) access and initialization
- login to zitadel https://zitadel.cc004.perf004.mojaperflab.org/

the default user is rootauto@zitadel.zitadel.cc004.perf004.mojaperflab.org with password #Password1!

- Create a new user for u # ndelma@mojaloop.io  #Password1! -> gagsac-wyvja3-johxyN. All other portal will authenticate users using zitadel.

- Give authorisation to new user using root user

- Login to zitadel using new user (don't use system users)

- Login to https://gitlab.cc004.perf004.mojaperflab.org

- open https://netbird-dashboard.cc004.perf004.mojaperflab.org to get the netclient configuration URL

- install netclient on the PC and edit in settings the management and admin URL

- login https://argocd.int.cc004.perf004.mojaperflab.org

- Sync netbird-post-config app in argocd

- login https://vault.int.cc004.perf004.mojaperflab.org/ with OIDC

- login https://grafana.int.cc004.perf004.mojaperflab.org/



# How to
## AWS Quota
│ Error: waiting for Auto Scaling Group (cc-master-generic-master20250522130607897100000015) capacity satisfied: scaling activity (bca65be0-680b-0961-cbd0-7ea7317543b2): Failed: You have requested more vCPU capacity than your current vCPU limit of 32 allows for the instance bucket that the specified instance type belongs to. Please visit http://aws.amazon.com/contact-us/ec2-request to request an adjustment to this limit. Launching EC2 instance failed.
│
│   with aws_autoscaling_group.node["master-generic"],
│   on infra.tf line 158, in resource "aws_autoscaling_group" "node":
│  158: resource "aws_autoscaling_group" "node" {
│
╵
solution: raise the requet to AWS to increate the quota

## iac_group
│ Error: assigning IAM User Group Membership (cc.perf004.mojaperflab.org-ci): adding User (cc.perf004.mojaperflab.org-ci) to Group (iac_admin): operation error IAM: AddUserToGroup, https response error StatusCode: 404, RequestID: ac0542a8-412e-4c7d-bd93-13a445394130, NoSuchEntity: The group with name iac_admin cannot be found.
│
│   with module.post_config.aws_iam_user_group_membership.iac_group[0],
│   on ../post-config-k8s/iam.tf line 12, in resource "aws_iam_user_group_membership" "iac_group":
│   12: resource "aws_iam_user_group_membership" "iac_group" {

solution: create the missing group

## Destroy the control center
from the control center util who deployed the control center
```bash
cd /iac-run-dir/iac-modules/terraform/ccnew/
source externalrunner.sh
source scripts/setlocalvars.sh
./movestatefromk8s.sh
terragrunt run-all destroy --terragrunt-non-interactive

```
## Solve lock caused by interrupted destroy

```
│ Error: Error acquiring the state lock
│
│ Error message: resource temporarily unavailable
│ Lock Info:
│   ID:        975b94dd-bcf6-8b80-a450-648d3d39f6b4
│   Path:      /iac-run-dir/iac-modules/terraform/ccnew/ansible-k8s-deploy/terraform.tfstate
│   Operation: OperationTypeApply
│   Who:       root@ml-ccu-gtmlab13
│   Version:   1.3.2
│   Created:   2025-05-22 11:31:54.769565373 +0000 UTC
│   Info:
│
│
│ Terraform acquires a state lock to protect the state from being written
│ by multiple users at the same time. Please resolve the issue above and try
│ again. For most commands, you can disable locking with the "-lock=false"
│ flag, but this is not recommended.
```

```bash
terragrunt force-unlock 975b94dd-bcf6-8b80-a450-648d3d39f6b4
```

## Work around destroy
after the primary way fail
```bash
cd /iac-run-dir/iac-modules/terraform/ccnew/k8s-deploy
terragrunt run-all destroy --terragrunt-non-interactive
```

## Modify env list 
- create/edit custom-config/environment.yaml 
- run refresh env template

## Expand storage in ubuntu

```bash
sudo lsblk
sudo growpart /dev/nvme0n1 1
sudo resize2fs /dev/nvme0n1p1
```


##
```bash

```
